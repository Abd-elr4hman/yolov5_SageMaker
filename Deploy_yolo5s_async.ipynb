{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "480241aa",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "947910bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import time\n",
    "from time import strftime,gmtime\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import boto3\n",
    "\n",
    "import os\n",
    "import io\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from sagemaker.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef46ab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role, Session, image_uris\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = Session()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ca48ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "boto_session = boto3.session.Session()\n",
    "sm_runtime = boto_session.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d73101",
   "metadata": {},
   "source": [
    "### Create model archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e90d93e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_archive_name = 'yolo5smodel-video.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fa6965b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.pth\r\n"
     ]
    }
   ],
   "source": [
    "!tar -cvzf {model_archive_name} model.pth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9259936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model package tarball (model artifact + inference code)\n",
    "model_url = sess.upload_data(path=model_archive_name, key_prefix='model')\n",
    "print('model uploaded to: {}'.format(model_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3f67a3",
   "metadata": {},
   "source": [
    "### Deploy Realtime Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "578a2026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "framework_version = '1.7.1'\n",
    "py_version = 'py36'\n",
    "env= {\n",
    "            'TS_MAX_REQUEST_SIZE': '1000000000', #default max request size is 6 Mb for torchserve, need to update it to support the 70 mb input payload\n",
    "            'TS_MAX_RESPONSE_SIZE': '1000000000',\n",
    "            'TS_DEFAULT_RESPONSE_TIMEOUT': '1000'\n",
    "        }\n",
    "\n",
    "sm_model = PyTorchModel(model_data=model_url,\n",
    "                               framework_version=framework_version,\n",
    "                               role=role,\n",
    "                               sagemaker_session=sess,\n",
    "                               entry_point='inference.py',\n",
    "                               source_dir= 'code',\n",
    "                               env=env,\n",
    "                               py_version=py_version\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2c755f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "instance_type = 'ml.g4dn.xlarge'\n",
    "uncompiled_predictor = sm_model.deploy(initial_instance_count=1, instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2bcf01",
   "metadata": {},
   "source": [
    "# Invoke model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb01eb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_data = io.open('test_images/bus.jpg', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a7a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(feed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8e0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "rv = sm_client.invoke_endpoint(EndpointName=uncompiled_predictor.endpoint_name, Body=feed_data, ContentType=content_type)\n",
    "t1 = time.time()\n",
    "\n",
    "time_elapsed = (t1-t0)*1000\n",
    "print(time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35bc36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= json.loads(rv['Body'].read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754e284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_arr = np.array(predictions)\n",
    "predictions_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f108c154",
   "metadata": {},
   "source": [
    "# Deploy Async Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8b3fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket= '' # output bucket name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b754cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.async_inference.async_inference_config import AsyncInferenceConfig\n",
    "\n",
    "async_config = AsyncInferenceConfig(\n",
    "                output_path= f\"s3://{bucket}/output\",\n",
    "                max_concurrent_invocations_per_instance=2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f770e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "framework_version = '1.7.1'\n",
    "py_version = 'py36'\n",
    "env= {\n",
    "            'TS_MAX_REQUEST_SIZE' : '1000000000', #default max request size is 6 Mb for torchserve, need to update it to support the 70 mb input payload\n",
    "            'TS_MAX_RESPONSE_SIZE': '1000000000',\n",
    "            'TS_DEFAULT_RESPONSE_TIMEOUT': '1000'\n",
    "        }\n",
    "\n",
    "sm_model = PyTorchModel(model_data=model_url,\n",
    "                               framework_version=framework_version,\n",
    "                               role=role,\n",
    "                               sagemaker_session=sess,\n",
    "                               entry_point='inference.py',\n",
    "                               source_dir= 'code',\n",
    "                               env=env,\n",
    "                               py_version=py_version\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d32d2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "instance_type = 'ml.g4dn.xlarge'\n",
    "\n",
    "async_uncompiled_predictor = sm_model.deploy(async_inference_config=async_config,\n",
    "                                       initial_instance_count=1,\n",
    "                                       instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a25e0e",
   "metadata": {},
   "source": [
    "# Test endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bbeec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload input top s3\n",
    "def upload_file(input_location):\n",
    "    prefix = \"input\"\n",
    "    return sess.upload_data(\n",
    "        input_location, \n",
    "        bucket = '',   # Input bucket name\n",
    "        key_prefix=prefix\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a6cbeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1_location = ''   # path to inference video \n",
    "input_1_s3_location = upload_file(input_1_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f168a6ea",
   "metadata": {},
   "source": [
    "### Invoke async endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d020106",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name= 'pytorch-inference-2022-10-17-12-07-29-325'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca60973",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm_runtime.invoke_endpoint_async(\n",
    "    EndpointName=endpoint_name, \n",
    "    InputLocation=input_1_s3_location)\n",
    "output_location = response['OutputLocation']\n",
    "print(f\"OutputLocation: {output_location}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('yolo_v5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ea8adc04bd2a79164fd69627b8007c30935a8b250d18f6ad06d7268a2523d0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
